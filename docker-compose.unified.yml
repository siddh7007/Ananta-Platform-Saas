# =============================================================================
# Ananta Platform SaaS - Unified Docker Compose
# =============================================================================
#
# This file combines Control Plane, App Plane, and Shared Infrastructure
# with CORRECT dependency ordering to prevent cascading failures.
#
# STARTUP ORDER:
# 1. Databases (postgres, redis, mongodb, etc.)
# 2. Shared Infrastructure (Temporal, Message Brokers)
# 3. Identity Provider (Keycloak)
# 4. Backend Services (tenant-mgmt, cns-service, etc.)
# 5. Workers (temporal-worker, cns-worker)
# 6. Frontend Applications
#
# Quick Start:
#   docker-compose -f docker-compose.unified.yml up -d
#   docker-compose -f docker-compose.unified.yml logs -f
#   docker-compose -f docker-compose.unified.yml down
#
# Start specific profiles:
#   docker-compose -f docker-compose.unified.yml --profile core up -d
#   docker-compose -f docker-compose.unified.yml --profile app-plane up -d
#   docker-compose -f docker-compose.unified.yml --profile full up -d
#
# =============================================================================

version: "3.8"

services:
  # ===========================================================================
  # LAYER 1: DATABASES (No dependencies - Start First)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # PostgreSQL - Control Plane Database
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: arc-saas-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: arc_saas
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./arc-saas/docker/init-db:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Temporal PostgreSQL - Workflow Engine Database
  # ---------------------------------------------------------------------------
  temporal-postgresql:
    image: postgres:15-alpine
    container_name: shared-temporal-postgres
    environment:
      POSTGRES_USER: temporal
      POSTGRES_PASSWORD: temporal
      POSTGRES_DB: temporal
    volumes:
      - temporal-postgres-data:/var/lib/postgresql/data
    ports:
      - "27030:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U temporal -d temporal"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Supabase PostgreSQL - App Plane Tenant Data
  # ---------------------------------------------------------------------------
  supabase-db:
    image: supabase/postgres:15.1.0.147
    container_name: app-plane-supabase-db
    environment:
      POSTGRES_PASSWORD: ${SUPABASE_DB_PASSWORD:-postgres}
      POSTGRES_USER: postgres
      POSTGRES_DB: postgres
    volumes:
      - supabase-db-data:/var/lib/postgresql/data
      - ./app-plane/supabase/init:/docker-entrypoint-initdb.d
    ports:
      - "27432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Components V2 PostgreSQL - Component Catalog SSOT
  # ---------------------------------------------------------------------------
  components-v2-postgres:
    image: postgres:15-alpine
    container_name: app-plane-components-v2-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: components_v2
    volumes:
      - components-v2-postgres-data:/var/lib/postgresql/data
      - ./app-plane/database/components-v2-init:/docker-entrypoint-initdb.d
    ports:
      - "27010:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d components_v2"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Redis - Control Plane Cache
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: arc-saas-redis
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Redis - App Plane Cache
  # ---------------------------------------------------------------------------
  redis-app:
    image: redis:7-alpine
    container_name: app-plane-redis
    command: redis-server --appendonly yes
    volumes:
      - redis-app-data:/data
    ports:
      - "27012:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # MongoDB - Novu Database
  # ---------------------------------------------------------------------------
  novu-mongodb:
    image: mongo:6
    container_name: arc-saas-novu-mongo
    volumes:
      - novu-mongo-data:/data/db
    ports:
      - "27017:27017"
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # RabbitMQ - Message Broker
  # ---------------------------------------------------------------------------
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: app-plane-rabbitmq
    ports:
      - "27672:5672"
      - "27673:15672"
      - "27692:15692"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
      RABBITMQ_DEFAULT_VHOST: /
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ===========================================================================
  # LAYER 2: SHARED INFRASTRUCTURE (Depends on Databases)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Temporal Server - Workflow Engine (SHARED)
  # ---------------------------------------------------------------------------
  temporal:
    image: temporalio/auto-setup:1.24.2
    container_name: shared-temporal
    depends_on:
      temporal-postgresql:
        condition: service_healthy
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=temporal-postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=false
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    ports:
      - "27020:7233"
    volumes:
      - ./arc-saas/temporal-config:/etc/temporal/config/dynamicconfig
    healthcheck:
      test: ["CMD", "temporal", "workflow", "list", "--namespace", "default"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 60s
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Temporal Web UI
  # ---------------------------------------------------------------------------
  temporal-ui:
    image: temporalio/ui:2.26.2
    container_name: shared-temporal-ui
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000,http://localhost:8080,http://localhost:27555
      - TEMPORAL_UI_PORT=8080
      - TEMPORAL_NOTIFY_ON_NEW_VERSION=false
    ports:
      - "27021:8080"
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Temporal Admin Tools (for namespace management)
  # ---------------------------------------------------------------------------
  temporal-admin-tools:
    image: temporalio/admin-tools:1.24.2
    container_name: shared-temporal-admin
    depends_on:
      temporal:
        condition: service_healthy
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    # Create namespaces on startup
    entrypoint: >
      /bin/sh -c "
        echo 'Waiting for Temporal to be ready...';
        sleep 10;
        echo 'Creating arc-saas namespace...';
        temporal operator namespace create arc-saas --address temporal:7233 || true;
        echo 'Creating enrichment namespace...';
        temporal operator namespace create enrichment --address temporal:7233 || true;
        echo 'Namespaces created. Keeping container alive...';
        tail -f /dev/null
      "
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # MinIO - Control Plane Object Storage
  # ---------------------------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: arc-saas-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    volumes:
      - minio-data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # MinIO - App Plane Object Storage
  # ---------------------------------------------------------------------------
  minio-app:
    image: minio/minio:latest
    container_name: app-plane-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-app-data:/data
    ports:
      - "27040:9000"
      - "27041:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # MinIO Init - Create Buckets
  # ---------------------------------------------------------------------------
  minio-init:
    image: minio/mc:latest
    container_name: arc-saas-minio-init
    depends_on:
      minio:
        condition: service_healthy
      minio-app:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set ctrl http://minio:9000 minioadmin minioadmin123;
      mc mb ctrl/arc-saas-tenants --ignore-existing;
      mc mb ctrl/arc-saas-assets --ignore-existing;
      mc mb ctrl/arc-saas-backups --ignore-existing;
      mc mb ctrl/novu-storage --ignore-existing;
      mc anonymous set download ctrl/arc-saas-assets;
      mc alias set app http://minio-app:9000 minioadmin minioadmin;
      mc mb app/bom-uploads --ignore-existing;
      mc mb app/documents --ignore-existing;
      mc mb app/exports --ignore-existing;
      mc mb app/avatars --ignore-existing;
      mc mb app/enrichment-audit --ignore-existing;
      mc mb app/bulk-uploads --ignore-existing;
      mc anonymous set download app/avatars;
      echo 'All MinIO buckets initialized successfully';
      exit 0;
      "
    networks:
      - shared-network

  # ---------------------------------------------------------------------------
  # Jaeger - Distributed Tracing
  # ---------------------------------------------------------------------------
  jaeger:
    image: jaegertracing/all-in-one:1.53
    container_name: arc-saas-jaeger
    environment:
      COLLECTOR_OTLP_ENABLED: true
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "4317:4317"
      - "4318:4318"
    networks:
      - shared-network
    restart: unless-stopped

  # ===========================================================================
  # LAYER 3: IDENTITY PROVIDER (Depends on Database)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Keycloak - Identity Provider
  # ---------------------------------------------------------------------------
  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    container_name: arc-saas-keycloak
    command: start-dev
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: postgres
      KC_DB_PASSWORD: postgres
      KC_HEALTH_ENABLED: true
    ports:
      - "8180:8080"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e 'GET /health/ready HTTP/1.1\r\nhost: localhost\r\nConnection: close\r\n\r\n' >&3;if [ $? -eq 0 ]; then echo 'Healthcheck Successful';exit 0;else echo 'Healthcheck Failed';exit 1;fi;"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - shared-network
    restart: unless-stopped

  # ===========================================================================
  # LAYER 4: NOTIFICATION SERVICES (Depends on MongoDB, Redis)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Novu Redis
  # ---------------------------------------------------------------------------
  novu-redis:
    image: redis:7-alpine
    container_name: arc-saas-novu-redis
    volumes:
      - novu-redis-data:/data
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Novu API
  # ---------------------------------------------------------------------------
  novu-api:
    image: ghcr.io/novuhq/novu/api:latest
    container_name: arc-saas-novu-api
    depends_on:
      novu-mongodb:
        condition: service_healthy
      novu-redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      NODE_ENV: production
      API_ROOT_URL: http://localhost:13100
      DISABLE_USER_REGISTRATION: "false"
      PORT: 3000
      FRONT_BASE_URL: http://localhost:14200
      WIDGET_BASE_URL: http://localhost:14200
      GLOBAL_CONTEXT_PATH: ""
      MONGO_URL: mongodb://novu-mongodb:27017/novu-db
      REDIS_HOST: novu-redis
      REDIS_PORT: 6379
      REDIS_CACHE_SERVICE_HOST: novu-redis
      REDIS_CACHE_SERVICE_PORT: 6379
      S3_LOCAL_STACK: http://minio:9000
      S3_BUCKET_NAME: novu-storage
      S3_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin123
      JWT_SECRET: your-jwt-secret-change-in-production
      STORE_ENCRYPTION_KEY: novuencryptionkey32charslong1234
      NOVU_SECRET_KEY: novu_secret_key_for_arc_saas
    ports:
      - "13100:3000"
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Novu Worker
  # ---------------------------------------------------------------------------
  novu-worker:
    image: ghcr.io/novuhq/novu/worker:latest
    container_name: arc-saas-novu-worker
    depends_on:
      - novu-mongodb
      - novu-redis
      - novu-api
    environment:
      NODE_ENV: production
      MONGO_URL: mongodb://novu-mongodb:27017/novu-db
      REDIS_HOST: novu-redis
      REDIS_PORT: 6379
      REDIS_CACHE_SERVICE_HOST: novu-redis
      REDIS_CACHE_SERVICE_PORT: 6379
      JWT_SECRET: your-jwt-secret-change-in-production
      STORE_ENCRYPTION_KEY: novuencryptionkey32charslong1234
      NOVU_SECRET_KEY: novu_secret_key_for_arc_saas
      API_ROOT_URL: http://novu-api:3000
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Novu WebSocket
  # ---------------------------------------------------------------------------
  novu-ws:
    image: ghcr.io/novuhq/novu/ws:latest
    container_name: arc-saas-novu-ws
    depends_on:
      - novu-mongodb
      - novu-redis
    environment:
      NODE_ENV: production
      PORT: 3002
      MONGO_URL: mongodb://novu-mongodb:27017/novu-db
      REDIS_HOST: novu-redis
      REDIS_PORT: 6379
      JWT_SECRET: your-jwt-secret-change-in-production
    ports:
      - "13101:3002"
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Novu Web Dashboard
  # ---------------------------------------------------------------------------
  novu-web:
    image: ghcr.io/novuhq/novu/web:latest
    container_name: arc-saas-novu-web
    depends_on:
      - novu-api
      - novu-ws
    environment:
      REACT_APP_API_URL: http://localhost:13100
      REACT_APP_WS_URL: http://localhost:13101
      REACT_APP_WIDGET_EMBED_PATH: http://localhost:13100/embed.umd.min.js
      REACT_APP_NOVU_APP_ID: arc-saas
      REACT_APP_LAUNCH_DARKLY_CLIENT_SIDE_ID: ""
      REACT_APP_SEGMENT_KEY: ""
      REACT_APP_HUBSPOT_EMBED: ""
      REACT_APP_INTERCOM_APP_ID: ""
      API_ROOT_URL: http://novu-api:3000
    ports:
      - "14200:4200"
    networks:
      - shared-network
    restart: unless-stopped

  # ===========================================================================
  # LAYER 5: SUPABASE SERVICES (Depends on supabase-db)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Supabase PostgREST API
  # ---------------------------------------------------------------------------
  supabase-api:
    image: postgrest/postgrest:v11.2.2
    container_name: app-plane-supabase-api
    ports:
      - "27810:3000"
    environment:
      PGRST_DB_URI: postgres://postgres:postgres@supabase-db:5432/postgres
      PGRST_DB_SCHEMA: public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: your-super-secret-jwt-token-with-at-least-32-characters-long
      PGRST_DB_EXTRA_SEARCH_PATH: public,extensions
      PGRST_SERVER_CORS_ALLOWED_ORIGINS: "http://localhost:27100,http://localhost:27555"
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Supabase Meta
  # ---------------------------------------------------------------------------
  supabase-meta:
    image: supabase/postgres-meta:v0.74.0
    container_name: app-plane-supabase-meta
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: supabase-db
      PG_META_DB_PORT: 5432
      PG_META_DB_NAME: postgres
      PG_META_DB_USER: postgres
      PG_META_DB_PASSWORD: postgres
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Supabase Studio
  # ---------------------------------------------------------------------------
  supabase-studio:
    image: supabase/studio:latest
    container_name: app-plane-supabase-studio
    ports:
      - "27800:3000"
    environment:
      STUDIO_PG_META_URL: http://supabase-meta:8080
      POSTGRES_PASSWORD: postgres
      SUPABASE_URL: http://supabase-api:3000
      SUPABASE_REST_URL: http://supabase-api:3000/rest/v1/
    networks:
      - shared-network
    depends_on:
      - supabase-db
      - supabase-meta
    restart: unless-stopped

  # ===========================================================================
  # LAYER 6: BACKEND SERVICES (Depends on Databases, Temporal, Keycloak)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Tenant Management Service (Control Plane API)
  # ---------------------------------------------------------------------------
  tenant-management-service:
    build:
      context: ./arc-saas/services/tenant-management-service
      dockerfile: Dockerfile
    container_name: arc-saas-tenant-mgmt
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      temporal:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    environment:
      NODE_ENV: development
      PORT: 14000
      HOST: 0.0.0.0
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: postgres
      DB_DATABASE: arc_saas
      DB_SCHEMA: main
      REDIS_HOST: redis
      REDIS_PORT: 6379
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_NAMESPACE: arc-saas
      JWT_SECRET: arc-saas-jwt-secret-change-in-production
      JWT_ISSUER: http://localhost:8180/realms/ananta-saas
      JWT_AUDIENCE: cbp-frontend
      LEAD_TOKEN_EXPIRY: "86400"
      LEAD_KEY_LENGTH: "36"
      VALIDATION_TOKEN_EXPIRY: "300000"
      KEYCLOAK_ENABLED: "true"
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_REALM: ananta-saas
      NOVU_ENABLED: "true"
      NOVU_API_KEY: ${NOVU_API_KEY:-}
      NOVU_BACKEND_URL: http://novu-api:3000
    ports:
      - "14000:14000"
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # CNS Service (FastAPI - Component Normalization)
  # ---------------------------------------------------------------------------
  cns-service:
    build:
      context: ./app-plane/services/cns-service
      dockerfile: Dockerfile
      target: development
    container_name: app-plane-cns-service
    ports:
      - "27200:8000"
    environment:
      NODE_ENV: development
      CNS_PORT: 8000
      CNS_HOST: 0.0.0.0
      LOG_LEVEL: DEBUG
      ENVIRONMENT: development
      DATABASE_URL: postgresql://postgres:postgres@components-v2-postgres:5432/components_v2
      SUPABASE_DATABASE_URL: postgresql://postgres:postgres@supabase-db:5432/postgres
      COMPONENTS_V2_DATABASE_URL: postgresql://postgres:postgres@components-v2-postgres:5432/components_v2
      DB_HOST: supabase-db
      DB_PORT: 5432
      DB_NAME: postgres
      DB_USER: postgres
      DB_PASSWORD: postgres
      DATABASE_POOL_SIZE: 20
      DATABASE_MAX_OVERFLOW: 10
      REDIS_URL: redis://redis-app:6379/2
      REDIS_CACHE_TTL: 3600
      JWT_SECRET_KEY: cns-jwt-secret-key-change-in-production-at-least-32-chars
      JWT_ALGORITHM: HS256
      JWT_EXPIRATION: 3600
      AUTH0_ENABLED: "true"
      AUTH0_DOMAIN: keycloak:8080/realms/ananta-saas
      AUTH0_AUDIENCE: cbp-frontend,cns-api,account
      AUTH0_NAMESPACE: https://ananta.component.platform
      ADMIN_API_TOKEN: f3ab7e1b4c9d2e7f1a3b5c7d9e0f1234567890abcdef1234567890abcdef
      CNS_ADMIN_API_TOKEN: f3ab7e1b4c9d2e7f1a3b5c7d9e0f1234567890abcdef1234567890abcdef
      ALLOW_DEV_DEFAULTS: "true"
      TEMPORAL_ENABLED: "true"
      TEMPORAL_HOST: temporal:7233
      TEMPORAL_URL: temporal:7233
      TEMPORAL_NAMESPACE: enrichment
      TEMPORAL_TASK_QUEUE: cns-enrichment
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: admin
      RABBITMQ_PASS: admin123
      RABBITMQ_VHOST: /
      MINIO_ENABLED: "true"
      MINIO_ENDPOINT: minio-app:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
      MINIO_SECURE: "false"
      MINIO_BUCKET_UPLOADS: bom-uploads
      MINIO_BUCKET_RESULTS: enriched-results
      MINIO_BUCKET_ARCHIVE: bulk-uploads-archive
      S3_BUCKET_NAME: bom-uploads
      S3_BUCKET_AUDIT: enrichment-audit
      S3_BUCKET_BULK: bulk-uploads
      ENABLE_AI_SUGGESTIONS: "true"
      DEBUG: "true"
    volumes:
      - ./app-plane/services/cns-service/app:/app/app
      - ./app-plane/services/cns-service/tests:/app/tests
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
      components-v2-postgres:
        condition: service_healthy
      redis-app:
        condition: service_healthy
      minio-app:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      temporal:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    restart: unless-stopped

  # ===========================================================================
  # LAYER 7: WORKERS (Depends on Backend Services, Temporal)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Temporal Worker Service (Control Plane)
  # ---------------------------------------------------------------------------
  temporal-worker-service:
    build:
      context: ./arc-saas/services/temporal-worker-service
      dockerfile: Dockerfile
    container_name: arc-saas-temporal-worker
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
      temporal:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    environment:
      NODE_ENV: development
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_NAMESPACE: arc-saas
      TEMPORAL_TASK_QUEUE: tenant-provisioning
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: postgres
      DB_DATABASE: arc_saas
      DB_SCHEMA: main
      S3_ENDPOINT: http://minio:9000
      AWS_REGION: us-east-1
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin123
      KEYCLOAK_ENABLED: "true"
      KEYCLOAK_URL: http://keycloak:8080
      KEYCLOAK_REALM: ananta-saas
      NOVU_ENABLED: "true"
      NOVU_BACKEND_URL: http://novu-api:3000
      OPENTELEMETRY_HOST: jaeger
      OPENTELEMETRY_PORT: 6832
      APP_PLANE_WEBHOOK_URL: http://webhook-bridge:27600
      APP_PLANE_WEBHOOK_SECRET: your-webhook-secret
    networks:
      - shared-network
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # CNS Temporal Worker (BOM Enrichment)
  # ---------------------------------------------------------------------------
  cns-worker:
    image: app-plane-cns-service
    container_name: app-plane-cns-worker
    command: python -m app.workers.bom_worker
    environment:
      NODE_ENV: development
      LOG_LEVEL: DEBUG
      ENVIRONMENT: development
      DATABASE_URL: postgresql://postgres:postgres@components-v2-postgres:5432/components_v2
      SUPABASE_DATABASE_URL: postgresql://postgres:postgres@supabase-db:5432/postgres
      COMPONENTS_V2_DATABASE_URL: postgresql://postgres:postgres@components-v2-postgres:5432/components_v2
      DB_HOST: supabase-db
      DB_PORT: 5432
      DB_NAME: postgres
      DB_USER: postgres
      DB_PASSWORD: postgres
      DATABASE_POOL_SIZE: 10
      DATABASE_MAX_OVERFLOW: 5
      REDIS_URL: redis://redis-app:6379/2
      REDIS_CACHE_TTL: 3600
      JWT_SECRET_KEY: cns-jwt-secret-key-change-in-production-at-least-32-chars
      JWT_ALGORITHM: HS256
      JWT_EXPIRATION: 3600
      TEMPORAL_ENABLED: "true"
      TEMPORAL_HOST: temporal:7233
      TEMPORAL_URL: temporal:7233
      TEMPORAL_NAMESPACE: enrichment
      TEMPORAL_TASK_QUEUE: cns-enrichment
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: admin
      RABBITMQ_PASS: admin123
      RABBITMQ_VHOST: /
      MINIO_ENABLED: "true"
      MINIO_ENDPOINT: minio-app:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      MINIO_SECURE: "false"
      MINIO_BUCKET_UPLOADS: bom-uploads
      MINIO_BUCKET_RESULTS: enriched-results
      S3_BUCKET_NAME: bom-uploads
      S3_BUCKET_AUDIT: enrichment-audit
      ENABLE_AI_SUGGESTIONS: "true"
      DEBUG: "true"
    volumes:
      - ./app-plane/services/cns-service/app:/app/app
      - ./app-plane/services/cns-service/tests:/app/tests
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
      components-v2-postgres:
        condition: service_healthy
      redis-app:
        condition: service_healthy
      temporal:
        condition: service_healthy
      cns-service:
        condition: service_healthy
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Webhook Bridge - Control Plane Integration
  # ---------------------------------------------------------------------------
  webhook-bridge:
    build:
      context: ./app-plane/webhook-bridge
      dockerfile: Dockerfile
    container_name: app-plane-webhook-bridge
    ports:
      - "27600:27600"
    environment:
      WEBHOOK_SECRET: your-webhook-secret
      SUPABASE_URL: http://supabase-api:3000
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_ROLE_KEY:-}
      FLASK_ENV: development
    volumes:
      - ./app-plane/webhook-bridge:/app
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
    restart: unless-stopped

  # ---------------------------------------------------------------------------
  # Audit Logger (RabbitMQ Consumer)
  # ---------------------------------------------------------------------------
  audit-logger:
    build:
      context: ./app-plane
      dockerfile: services/audit-logger/Dockerfile
    container_name: app-plane-audit-logger
    environment:
      DATABASE_URL: postgres://postgres:postgres@supabase-db:5432/postgres
      SUPABASE_DB_HOST: supabase-db
      SUPABASE_DB_PORT: 5432
      SUPABASE_DB_NAME: postgres
      SUPABASE_DB_USER: postgres
      SUPABASE_DB_PASSWORD: postgres
      DB_HOST: supabase-db
      DB_PORT: 5432
      DB_NAME: postgres
      DB_USER: postgres
      DB_PASSWORD: postgres
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: admin
      RABBITMQ_PASS: admin123
      LOG_LEVEL: DEBUG
      TEMPORAL_ENABLED: "true"
      TEMPORAL_HOST: temporal:7233
      TEMPORAL_URL: temporal:7233
      TEMPORAL_NAMESPACE: enrichment
      TEMPORAL_TASK_QUEUE: cns-enrichment
    volumes:
      - ./app-plane/services/audit-logger/app:/app
    networks:
      - shared-network
    depends_on:
      supabase-db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  # Control Plane
  postgres-data:
  redis-data:
  minio-data:
  novu-mongo-data:
  novu-redis-data:

  # Shared Temporal
  temporal-postgres-data:

  # App Plane
  supabase-db-data:
  components-v2-postgres-data:
  redis-app-data:
  rabbitmq-data:
  minio-app-data:

# =============================================================================
# NETWORKS - Single Shared Network for All Services
# =============================================================================
networks:
  shared-network:
    driver: bridge
    name: ananta-platform-network
